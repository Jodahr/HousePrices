{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from keras.callbacks import History , EarlyStopping, TensorBoard\n",
    "history = History()\n",
    "\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_regression(n_features=100, n_samples=10000, noise=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[0]\n",
    "y = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(X[0],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input, BatchNormalization, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00907949, -0.00189441,  0.00652062, -0.00644898, -0.01631431,\n",
       "        0.00106823,  0.00778035,  0.00808042,  0.00129312,  0.01214166,\n",
       "       -0.00700522, -0.01905682, -0.00071089, -0.01005718, -0.0195479 ,\n",
       "        0.00490721,  0.00393767, -0.00620955,  0.0019896 ,  0.0075504 ,\n",
       "       -0.00994499, -0.00264212, -0.00432919,  0.00446179,  0.0026477 ,\n",
       "       -0.0144071 , -0.00099685, -0.0091815 ,  0.00823751,  0.0004666 ,\n",
       "       -0.00425293, -0.0065793 , -0.01662812, -0.0214542 , -0.00884387,\n",
       "        0.00503281,  0.00363362,  0.0070218 ,  0.00885723, -0.00541894,\n",
       "       -0.00306412, -0.00276816,  0.00260981, -0.01263101,  0.00689427,\n",
       "       -0.01452086,  0.01970822, -0.01054998, -0.01235727,  0.00043658,\n",
       "       -0.0039561 ,  0.01086819,  0.01902443, -0.00435724,  0.00762432,\n",
       "        0.01766107,  0.00443224, -0.00970974, -0.00696154,  0.00276971,\n",
       "       -0.01119508, -0.01252567, -0.02008661,  0.01081543,  0.00769622,\n",
       "        0.00457605,  0.01008033, -0.00954041,  0.00050443,  0.00280299,\n",
       "       -0.00451628,  0.00235689,  0.00473677,  0.00680135, -0.00861983,\n",
       "        0.00754302,  0.02145016,  0.00826679,  0.00237998, -0.00298604,\n",
       "       -0.00437917, -0.00021022, -0.00122276, -0.00786593, -0.02016535,\n",
       "       -0.00567592, -0.00502613,  0.00866392, -0.00349224,  0.01279853,\n",
       "       -0.00185159,  0.00624787,  0.00063341,  0.00807169, -0.0074414 ,\n",
       "       -0.01268788, -0.00456128, -0.00632141, -0.01202908, -0.01780109])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.12976295e-16,  -3.04034575e-17,  -2.15938378e-18,\n",
       "         4.20774526e-17,   9.43245482e-17,   3.75255382e-18,\n",
       "         8.21565038e-18,   2.21767049e-17,   2.64011035e-17,\n",
       "         8.81128503e-17,   7.17204074e-18,  -9.63673585e-17,\n",
       "        -1.44328993e-19,  -8.39328607e-18,   1.50546242e-17,\n",
       "         1.38777878e-17,   3.76365605e-18,  -2.90878432e-18,\n",
       "        -1.97397654e-17,   3.52273766e-17,  -9.31865696e-17,\n",
       "        -9.47575352e-17,   4.92939023e-18,   5.22915045e-18,\n",
       "        -5.14810417e-17,  -5.97744076e-17,  -1.09606768e-17,\n",
       "         3.91908728e-18,   2.47801779e-17,   5.00655073e-17,\n",
       "        -3.92130772e-17,  -1.97286631e-17,  -1.50324198e-17,\n",
       "        -1.18682841e-17,  -1.44328993e-18,   1.76858528e-17,\n",
       "        -2.56905608e-17,  -2.87991853e-17,  -7.01105840e-18,\n",
       "         1.35114142e-17,  -3.61377595e-17,  -5.24025268e-18,\n",
       "         4.86277685e-18,   7.08988424e-17,  -4.83613150e-17,\n",
       "        -5.70876679e-17,  -5.27911048e-17,   2.10668288e-17,\n",
       "         4.20219415e-18,  -3.62793129e-17,  -2.31925590e-17,\n",
       "         1.62758695e-16,   6.97886193e-17,   5.36459765e-17,\n",
       "         2.08388862e-17,  -1.52500235e-16,   4.38316050e-17,\n",
       "        -1.93178806e-17,  -2.48340411e-17,  -5.69766456e-17,\n",
       "         6.39488462e-17,   4.48779902e-17,   7.60502772e-17,\n",
       "         2.93098879e-17,   3.00981462e-17,   2.13488949e-17,\n",
       "        -3.65485420e-17,   1.79078974e-17,   1.06359366e-17,\n",
       "         1.15019105e-17,  -2.93431945e-17,  -1.62536651e-17,\n",
       "        -4.09783318e-17,   1.35669254e-17,   8.99280650e-19,\n",
       "         5.06983344e-17,  -2.33146835e-17,  -3.04756220e-17,\n",
       "        -1.12632126e-17,  -1.01807451e-16,   2.48689958e-18,\n",
       "        -1.89515070e-17,   2.21989094e-17,  -5.56332758e-17,\n",
       "         1.10023102e-17,   1.45772283e-17,   2.14495088e-17,\n",
       "         2.03059791e-17,   4.96047647e-17,   8.19122548e-17,\n",
       "        -2.62290190e-17,   9.10382880e-18,   5.18807219e-17,\n",
       "         1.56763491e-17,   1.76303416e-17,   3.45279361e-17,\n",
       "         1.12021503e-17,   9.88098492e-19,   2.84217094e-17,\n",
       "        -1.34581235e-16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(X).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import keras.backend as K#\n",
    "\n",
    "#def custom_r2(y_true, y_pred):\n",
    "#    return K.mean(y_pred)\n",
    "\n",
    "# custom R2-score metrics for keras backend\n",
    "from keras import backend as K\n",
    "\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def myModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=100))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(100000,activation='relu'))\n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    #model.add(Dense(10, activation='linear'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam',\n",
    "                  metrics=['mse', 'mae', 'mape', r2_keras])\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=myModel)\n",
    "\n",
    "# train model\n",
    "#history = model.fit(X_train, y_train, epochs=1000, batch_size=len(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('NN', estimator)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg  = pipe.steps[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = reg.build_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 100000)            10100000  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100000)            0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1)                 100001    \n",
      "=================================================================\n",
      "Total params: 10,210,101\n",
      "Trainable params: 10,210,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = history.on_epoch_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method History.on_epoch_end of <keras.callbacks.History object at 0x7f1a9453b1d0>>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU vs GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6666/6666 [==============================] - 28s 4ms/step - loss: 3487.9354 - mean_squared_error: 3487.9354 - mean_absolute_error: 25.7519 - mean_absolute_percentage_error: 47.9021 - cosine_proximity: -0.8845\n",
      "Epoch 2/10\n",
      "6666/6666 [==============================] - 27s 4ms/step - loss: 12.3349 - mean_squared_error: 12.3349 - mean_absolute_error: 2.7658 - mean_absolute_percentage_error: 12.6978 - cosine_proximity: -0.9841\n",
      "Epoch 3/10\n",
      "6666/6666 [==============================] - 27s 4ms/step - loss: 14.7557 - mean_squared_error: 14.7557 - mean_absolute_error: 3.0176 - mean_absolute_percentage_error: 11.5101 - cosine_proximity: -0.9853\n",
      "Epoch 4/10\n",
      "6666/6666 [==============================] - 27s 4ms/step - loss: 50.2549 - mean_squared_error: 50.2549 - mean_absolute_error: 5.5560 - mean_absolute_percentage_error: 21.3599 - cosine_proximity: -0.9745\n",
      "Epoch 5/10\n",
      "6666/6666 [==============================] - 27s 4ms/step - loss: 74.5734 - mean_squared_error: 74.5734 - mean_absolute_error: 6.8028 - mean_absolute_percentage_error: 24.1895 - cosine_proximity: -0.9739\n",
      "Epoch 6/10\n",
      "6666/6666 [==============================] - 27s 4ms/step - loss: 54.1183 - mean_squared_error: 54.1183 - mean_absolute_error: 5.7965 - mean_absolute_percentage_error: 17.8503 - cosine_proximity: -0.9796\n",
      "Epoch 7/10\n",
      "3264/6666 [=============>................] - ETA: 13s - loss: 69.3197 - mean_squared_error: 69.3197 - mean_absolute_error: 6.5384 - mean_absolute_percentage_error: 28.8278 - cosine_proximity: -0.9779"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-3f63e4afe4d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with tf.device('/cpu:0'):\\n    cross_val_score(estimator=pipe, X=X, y=y, fit_params={'NN__epochs':10, 'NN__callbacks':[history]})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1581\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device('/cpu:0'):\n",
    "    cross_val_score(estimator=pipe, X=X, y=y, fit_params={'NN__epochs':10, 'NN__callbacks':[history]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6666/6666 [==============================] - 5s 752us/step - loss: 3285.0851 - mean_squared_error: 3285.0851 - mean_absolute_error: 25.9165 - mean_absolute_percentage_error: 84.9200 - r2_keras: 0.8888\n",
      "Epoch 2/10\n",
      "6666/6666 [==============================] - 4s 635us/step - loss: 15.3654 - mean_squared_error: 15.3654 - mean_absolute_error: 3.1043 - mean_absolute_percentage_error: 11.6021 - r2_keras: 0.9995\n",
      "Epoch 3/10\n",
      "6666/6666 [==============================] - 4s 637us/step - loss: 9.7880 - mean_squared_error: 9.7880 - mean_absolute_error: 2.4590 - mean_absolute_percentage_error: 9.2982 - r2_keras: 0.9997\n",
      "Epoch 4/10\n",
      "6666/6666 [==============================] - 4s 637us/step - loss: 29.2304 - mean_squared_error: 29.2304 - mean_absolute_error: 4.2269 - mean_absolute_percentage_error: 15.3371 - r2_keras: 0.9990\n",
      "Epoch 5/10\n",
      "6666/6666 [==============================] - 4s 642us/step - loss: 99.9944 - mean_squared_error: 99.9944 - mean_absolute_error: 7.9172 - mean_absolute_percentage_error: 28.5740 - r2_keras: 0.9966\n",
      "Epoch 6/10\n",
      "6666/6666 [==============================] - 4s 638us/step - loss: 68.1225 - mean_squared_error: 68.1225 - mean_absolute_error: 6.5173 - mean_absolute_percentage_error: 24.2530 - r2_keras: 0.9977\n",
      "Epoch 7/10\n",
      "6666/6666 [==============================] - 4s 637us/step - loss: 49.0328 - mean_squared_error: 49.0328 - mean_absolute_error: 5.4595 - mean_absolute_percentage_error: 20.5075 - r2_keras: 0.9983\n",
      "Epoch 8/10\n",
      "6666/6666 [==============================] - 4s 637us/step - loss: 45.0907 - mean_squared_error: 45.0907 - mean_absolute_error: 5.2579 - mean_absolute_percentage_error: 18.8713 - r2_keras: 0.9984\n",
      "Epoch 9/10\n",
      "6666/6666 [==============================] - 4s 637us/step - loss: 50.3080 - mean_squared_error: 50.3080 - mean_absolute_error: 5.5257 - mean_absolute_percentage_error: 18.3381 - r2_keras: 0.9983\n",
      "Epoch 10/10\n",
      "6666/6666 [==============================] - 4s 638us/step - loss: 59.9707 - mean_squared_error: 59.9707 - mean_absolute_error: 6.0738 - mean_absolute_percentage_error: 21.2596 - r2_keras: 0.9980\n",
      "3334/3334 [==============================] - 1s 209us/step\n",
      "Epoch 1/10\n",
      "6667/6667 [==============================] - ETA: 0s - loss: 3213.2802 - mean_squared_error: 3213.2802 - mean_absolute_error: 25.2949 - mean_absolute_percentage_error: 51.1600 - r2_keras: 0.88 - 5s 746us/step - loss: 3207.9958 - mean_squared_error: 3207.9958 - mean_absolute_error: 25.2570 - mean_absolute_percentage_error: 51.0826 - r2_keras: 0.8853\n",
      "Epoch 2/10\n",
      "6667/6667 [==============================] - 4s 637us/step - loss: 12.5736 - mean_squared_error: 12.5736 - mean_absolute_error: 2.8108 - mean_absolute_percentage_error: 9.4061 - r2_keras: 0.9995\n",
      "Epoch 3/10\n",
      "6667/6667 [==============================] - 4s 636us/step - loss: 10.0291 - mean_squared_error: 10.0291 - mean_absolute_error: 2.5106 - mean_absolute_percentage_error: 8.7462 - r2_keras: 0.9996\n",
      "Epoch 4/10\n",
      "6667/6667 [==============================] - 4s 638us/step - loss: 24.7615 - mean_squared_error: 24.7615 - mean_absolute_error: 3.9090 - mean_absolute_percentage_error: 14.0013 - r2_keras: 0.9991\n",
      "Epoch 5/10\n",
      "6667/6667 [==============================] - 4s 636us/step - loss: 122.0476 - mean_squared_error: 122.0476 - mean_absolute_error: 8.5609 - mean_absolute_percentage_error: 29.2793 - r2_keras: 0.9956\n",
      "Epoch 6/10\n",
      "6667/6667 [==============================] - 4s 636us/step - loss: 67.0563 - mean_squared_error: 67.0563 - mean_absolute_error: 6.4278 - mean_absolute_percentage_error: 20.6114 - r2_keras: 0.9976\n",
      "Epoch 7/10\n",
      "6667/6667 [==============================] - 4s 638us/step - loss: 25.5689 - mean_squared_error: 25.5689 - mean_absolute_error: 3.9974 - mean_absolute_percentage_error: 15.8310 - r2_keras: 0.9991\n",
      "Epoch 8/10\n",
      "6667/6667 [==============================] - 4s 641us/step - loss: 40.1720 - mean_squared_error: 40.1720 - mean_absolute_error: 4.9399 - mean_absolute_percentage_error: 17.4070 - r2_keras: 0.9986\n",
      "Epoch 9/10\n",
      "6667/6667 [==============================] - 4s 640us/step - loss: 72.3475 - mean_squared_error: 72.3475 - mean_absolute_error: 6.6035 - mean_absolute_percentage_error: 23.6808 - r2_keras: 0.9974\n",
      "Epoch 10/10\n",
      "6667/6667 [==============================] - 4s 640us/step - loss: 44.9590 - mean_squared_error: 44.9590 - mean_absolute_error: 5.2360 - mean_absolute_percentage_error: 19.7930 - r2_keras: 0.9984\n",
      "3333/3333 [==============================] - 1s 216us/step\n",
      "Epoch 1/10\n",
      "6667/6667 [==============================] - 5s 754us/step - loss: 3591.8420 - mean_squared_error: 3591.8420 - mean_absolute_error: 26.9712 - mean_absolute_percentage_error: 55.4220 - r2_keras: 0.8799\n",
      "Epoch 2/10\n",
      "6667/6667 [==============================] - ETA: 0s - loss: 13.2005 - mean_squared_error: 13.2005 - mean_absolute_error: 2.8912 - mean_absolute_percentage_error: 10.0954 - r2_keras: 0.999 - 4s 641us/step - loss: 13.1950 - mean_squared_error: 13.1950 - mean_absolute_error: 2.8909 - mean_absolute_percentage_error: 10.0905 - r2_keras: 0.9995\n",
      "Epoch 3/10\n",
      "6667/6667 [==============================] - 4s 640us/step - loss: 9.1524 - mean_squared_error: 9.1524 - mean_absolute_error: 2.4128 - mean_absolute_percentage_error: 8.2658 - r2_keras: 0.9997\n",
      "Epoch 4/10\n",
      "6667/6667 [==============================] - 4s 639us/step - loss: 19.9192 - mean_squared_error: 19.9192 - mean_absolute_error: 3.4153 - mean_absolute_percentage_error: 10.4014 - r2_keras: 0.9993\n",
      "Epoch 5/10\n",
      "6667/6667 [==============================] - 4s 634us/step - loss: 55.7109 - mean_squared_error: 55.7109 - mean_absolute_error: 5.8876 - mean_absolute_percentage_error: 16.8335 - r2_keras: 0.9980\n",
      "Epoch 6/10\n",
      "6667/6667 [==============================] - 4s 638us/step - loss: 45.6682 - mean_squared_error: 45.6682 - mean_absolute_error: 5.3564 - mean_absolute_percentage_error: 16.8745 - r2_keras: 0.9984\n",
      "Epoch 7/10\n",
      "6667/6667 [==============================] - 4s 639us/step - loss: 53.9550 - mean_squared_error: 53.9550 - mean_absolute_error: 5.7417 - mean_absolute_percentage_error: 18.1306 - r2_keras: 0.9981\n",
      "Epoch 8/10\n",
      "6667/6667 [==============================] - 4s 640us/step - loss: 92.5399 - mean_squared_error: 92.5399 - mean_absolute_error: 7.5643 - mean_absolute_percentage_error: 22.7491 - r2_keras: 0.9967\n",
      "Epoch 9/10\n",
      "6667/6667 [==============================] - 4s 641us/step - loss: 73.9128 - mean_squared_error: 73.9128 - mean_absolute_error: 6.6482 - mean_absolute_percentage_error: 20.9224 - r2_keras: 0.9973\n",
      "Epoch 10/10\n",
      "6667/6667 [==============================] - 4s 639us/step - loss: 28.1235 - mean_squared_error: 28.1235 - mean_absolute_error: 4.1789 - mean_absolute_percentage_error: 13.2829 - r2_keras: 0.9990\n",
      "3333/3333 [==============================] - 1s 222us/step\n",
      "CPU times: user 2min, sys: 29.9 s, total: 2min 30s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    cross_val_score(estimator=pipe, X=X, y=y, fit_params={'NN__epochs':10, 'NN__callbacks':[history]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [3591.8419777824547,\n",
       "  13.194988407508641,\n",
       "  9.1523868771923951,\n",
       "  19.919226301830356,\n",
       "  55.71087526441854,\n",
       "  45.66822297637102,\n",
       "  53.955036652540542,\n",
       "  92.539865107269534,\n",
       "  73.912820074786055,\n",
       "  28.123462778277101],\n",
       " 'mean_absolute_error': [26.971164764735015,\n",
       "  2.8908638690961648,\n",
       "  2.412798720212896,\n",
       "  3.4153453964727185,\n",
       "  5.8875533651872898,\n",
       "  5.3563727429196701,\n",
       "  5.7417250966961388,\n",
       "  7.5642630784644238,\n",
       "  6.6481727576066261,\n",
       "  4.1788736221510305],\n",
       " 'mean_absolute_percentage_error': [55.422028437536198,\n",
       "  10.090496568463813,\n",
       "  8.2658136212452078,\n",
       "  10.401399454220099,\n",
       "  16.833456586250144,\n",
       "  16.874503928073363,\n",
       "  18.130589489459776,\n",
       "  22.749054792457674,\n",
       "  20.922370490381272,\n",
       "  13.282851416864048],\n",
       " 'mean_squared_error': [3591.8419777824547,\n",
       "  13.194988407508641,\n",
       "  9.1523868771923951,\n",
       "  19.919226301830356,\n",
       "  55.71087526441854,\n",
       "  45.66822297637102,\n",
       "  53.955036652540542,\n",
       "  92.539865107269534,\n",
       "  73.912820074786055,\n",
       "  28.123462778277101],\n",
       " 'r2_keras': [0.87989566217785531,\n",
       "  0.99953467498677451,\n",
       "  0.99967269636763256,\n",
       "  0.99929688322646015,\n",
       "  0.99801609290670701,\n",
       "  0.99836395762931185,\n",
       "  0.99808031095277605,\n",
       "  0.99670494891042671,\n",
       "  0.997345724974112,\n",
       "  0.99900149679512962]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6666/6666 [==============================] - 4s 626us/step - loss: 3412.9502 - mean_squared_error: 3412.9502 - mean_absolute_error: 25.7473 - mean_absolute_percentage_error: 67.9399 - cosine_proximity: -0.8860\n",
      "Epoch 2/10\n",
      "6666/6666 [==============================] - 4s 552us/step - loss: 10.9504 - mean_squared_error: 10.9504 - mean_absolute_error: 2.6021 - mean_absolute_percentage_error: 11.2848 - cosine_proximity: -0.98503s - loss: 18.7725 - mean_squar\n",
      "Epoch 3/10\n",
      "6666/6666 [==============================] - 4s 552us/step - loss: 10.9540 - mean_squared_error: 10.9540 - mean_absolute_error: 2.6233 - mean_absolute_percentage_error: 10.8930 - cosine_proximity: -0.9868\n",
      "Epoch 4/10\n",
      "6666/6666 [==============================] - 4s 551us/step - loss: 27.6749 - mean_squared_error: 27.6749 - mean_absolute_error: 4.1375 - mean_absolute_percentage_error: 14.7254 - cosine_proximity: -0.9850\n",
      "Epoch 5/10\n",
      "6666/6666 [==============================] - 4s 552us/step - loss: 93.7495 - mean_squared_error: 93.7495 - mean_absolute_error: 7.6159 - mean_absolute_percentage_error: 23.7926 - cosine_proximity: -0.9724\n",
      "Epoch 6/10\n",
      "6666/6666 [==============================] - 4s 551us/step - loss: 64.2009 - mean_squared_error: 64.2009 - mean_absolute_error: 6.0413 - mean_absolute_percentage_error: 20.4858 - cosine_proximity: -0.9724\n",
      "Epoch 7/10\n",
      "6666/6666 [==============================] - 4s 551us/step - loss: 83.2719 - mean_squared_error: 83.2719 - mean_absolute_error: 7.0411 - mean_absolute_percentage_error: 19.5758 - cosine_proximity: -0.9742\n",
      "Epoch 8/10\n",
      "6666/6666 [==============================] - 4s 549us/step - loss: 31.4716 - mean_squared_error: 31.4716 - mean_absolute_error: 4.3745 - mean_absolute_percentage_error: 15.3110 - cosine_proximity: -0.9820\n",
      "Epoch 9/10\n",
      "6666/6666 [==============================] - 4s 548us/step - loss: 35.7837 - mean_squared_error: 35.7837 - mean_absolute_error: 4.4503 - mean_absolute_percentage_error: 16.0103 - cosine_proximity: -0.9853\n",
      "Epoch 10/10\n",
      "6666/6666 [==============================] - 4s 553us/step - loss: 131.2442 - mean_squared_error: 131.2442 - mean_absolute_error: 8.6884 - mean_absolute_percentage_error: 28.9068 - cosine_proximity: -0.9700\n",
      "Epoch 1/10\n",
      "6667/6667 [==============================] - 4s 632us/step - loss: 3329.9433 - mean_squared_error: 3329.9433 - mean_absolute_error: 26.2877 - mean_absolute_percentage_error: 60.3260 - cosine_proximity: -0.8746\n",
      "Epoch 2/10\n",
      "6667/6667 [==============================] - 4s 554us/step - loss: 11.3492 - mean_squared_error: 11.3492 - mean_absolute_error: 2.6521 - mean_absolute_percentage_error: 10.7396 - cosine_proximity: -0.9871\n",
      "Epoch 3/10\n",
      "6667/6667 [==============================] - 4s 549us/step - loss: 10.5767 - mean_squared_error: 10.5767 - mean_absolute_error: 2.5610 - mean_absolute_percentage_error: 10.0052 - cosine_proximity: -0.9874\n",
      "Epoch 4/10\n",
      "6667/6667 [==============================] - 4s 556us/step - loss: 50.9421 - mean_squared_error: 50.9421 - mean_absolute_error: 5.5743 - mean_absolute_percentage_error: 19.0947 - cosine_proximity: -0.9781\n",
      "Epoch 5/10\n",
      "6667/6667 [==============================] - 4s 554us/step - loss: 95.5544 - mean_squared_error: 95.5544 - mean_absolute_error: 7.7040 - mean_absolute_percentage_error: 26.5574 - cosine_proximity: -0.9682\n",
      "Epoch 6/10\n",
      "6667/6667 [==============================] - 4s 551us/step - loss: 37.7606 - mean_squared_error: 37.7606 - mean_absolute_error: 4.8421 - mean_absolute_percentage_error: 16.6342 - cosine_proximity: -0.97753s - loss: 35.\n",
      "Epoch 7/10\n",
      "6667/6667 [==============================] - 4s 555us/step - loss: 36.0809 - mean_squared_error: 36.0809 - mean_absolute_error: 4.6844 - mean_absolute_percentage_error: 16.6021 - cosine_proximity: -0.9799\n",
      "Epoch 8/10\n",
      "6667/6667 [==============================] - 4s 552us/step - loss: 29.8478 - mean_squared_error: 29.8478 - mean_absolute_error: 4.2073 - mean_absolute_percentage_error: 15.0212 - cosine_proximity: -0.9835\n",
      "Epoch 9/10\n",
      "6667/6667 [==============================] - 4s 552us/step - loss: 81.1918 - mean_squared_error: 81.1918 - mean_absolute_error: 7.0668 - mean_absolute_percentage_error: 22.4067 - cosine_proximity: -0.9757\n",
      "Epoch 10/10\n",
      "6667/6667 [==============================] - 4s 553us/step - loss: 32.3981 - mean_squared_error: 32.3981 - mean_absolute_error: 4.4387 - mean_absolute_percentage_error: 15.1311 - cosine_proximity: -0.9796\n",
      "Epoch 1/10\n",
      "6667/6667 [==============================] - 4s 636us/step - loss: 3298.0620 - mean_squared_error: 3298.0620 - mean_absolute_error: 25.3635 - mean_absolute_percentage_error: 75.3986 - cosine_proximity: -0.8863\n",
      "Epoch 2/10\n",
      "6667/6667 [==============================] - 4s 551us/step - loss: 11.5568 - mean_squared_error: 11.5568 - mean_absolute_error: 2.6823 - mean_absolute_percentage_error: 11.1753 - cosine_proximity: -0.9868\n",
      "Epoch 3/10\n",
      "6667/6667 [==============================] - 4s 554us/step - loss: 11.3050 - mean_squared_error: 11.3050 - mean_absolute_error: 2.6404 - mean_absolute_percentage_error: 8.6836 - cosine_proximity: -0.9889\n",
      "Epoch 4/10\n",
      "6667/6667 [==============================] - 4s 547us/step - loss: 27.8935 - mean_squared_error: 27.8935 - mean_absolute_error: 4.1599 - mean_absolute_percentage_error: 12.4502 - cosine_proximity: -0.9841\n",
      "Epoch 5/10\n",
      "6667/6667 [==============================] - 4s 550us/step - loss: 91.7776 - mean_squared_error: 91.7776 - mean_absolute_error: 7.2739 - mean_absolute_percentage_error: 20.8942 - cosine_proximity: -0.9691\n",
      "Epoch 6/10\n",
      "6667/6667 [==============================] - 4s 555us/step - loss: 81.6750 - mean_squared_error: 81.6750 - mean_absolute_error: 6.5796 - mean_absolute_percentage_error: 19.5784 - cosine_proximity: -0.9733\n",
      "Epoch 7/10\n",
      "6667/6667 [==============================] - 4s 549us/step - loss: 18.8622 - mean_squared_error: 18.8622 - mean_absolute_error: 3.4193 - mean_absolute_percentage_error: 11.2926 - cosine_proximity: -0.9850\n",
      "Epoch 8/10\n",
      "6667/6667 [==============================] - 4s 555us/step - loss: 56.2672 - mean_squared_error: 56.2672 - mean_absolute_error: 5.7124 - mean_absolute_percentage_error: 16.4657 - cosine_proximity: -0.9751\n",
      "Epoch 9/10\n",
      "6667/6667 [==============================] - 4s 551us/step - loss: 175.4039 - mean_squared_error: 175.4039 - mean_absolute_error: 9.7653 - mean_absolute_percentage_error: 27.0855 - cosine_proximity: -0.9646\n",
      "Epoch 10/10\n",
      "6667/6667 [==============================] - 4s 553us/step - loss: 51.4670 - mean_squared_error: 51.4670 - mean_absolute_error: 4.9860 - mean_absolute_percentage_error: 15.0613 - cosine_proximity: -0.9715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99578245,  0.9989904 ,  0.99983934])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=pipe, X=X, y=y,scoring='r2', fit_params={'NN__epochs':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16214274448064773804\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4980736\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 12145613270696571672\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:0c:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98, 1.0056615480771214)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAH3xJREFUeJzt3XmQnPV95/F39/SM5pZGMz06RgdI\nSF8QBJBkIzDGnC7bGBbHJutNOTEkoTZ2sQ6V7FHeMlmvnao4Xq8LJ8jlUN7CseNa42TNtYsxWJy2\nhTkkEIfEV0hIgDQ6ZnTMSDOS+tw/nu45hDRqeZ5WP9P9eVVNafp5nu7+PT9Jn+fXv+d5vh3L5/OI\niEhtiFe6ASIicuYo9EVEaohCX0Skhij0RURqiEJfRKSGJCrdgIn09R2a1KVFHR3NHDgwHFZzpjT1\nxXjqj/HUH6OqoS+SybbYydZV9Ug/kairdBMiQ30xnvpjPPXHqGrvi6oOfRERGa+k6R0zuwB4CLjL\n3Vcft+464G+BLPBzd/+bwvK7gEuBPHCHu79oZncDlwGHC0//lrs/EsqeiIjIKZ0y9M2sBbgbeOIk\nm/wD8DFgJ/BrM/sZkASWuPtlZrYM+AGwCmgFbnP3V8JovIiInJ5SpneOAdcDvcevMLNFwH53f8/d\nc8AjwLWFnwcB3H0j0GFm7UBbWA0XEZHTd8qRvrtngIyZnWj1bKBvzOPdwGKgC1g3ZvmewratwFfN\nrAPYAfyFu+8/2Xt3dDRP+qRKMqnjTJH6Yjz1x3jqj1HV3BeTvWTz+MuCYgRz+Cdbfg/whrtvNrOv\nAF8DvnSyF5/sZVPJZBt9fYcm9RrVQn0xnvpjPPXHqGroi4kOWpMN/Z0EI/iiHmAXkD5u+Vxgt7u/\nNWbZA8D3Jvn+IiJyGiZ1yaa7bwfazewsM0sANwCPF35uBjCz5UCvux8ys4fNbEHh6VcBr0/m/UVE\n5PSUcvXOSuDbwFlA2sxuBh4Gtrn7A8AXgZ8UNv+pu28GNpvZOjNbC+SA2wvrVwM/M7MhYAj4kzB3\nRkREJhaL8peoTLYMQzXMzYVFfTGe+mM89ceoauiLmi3DICIi4yn0RURqiEJfRKSGKPRFRGqIQl9E\npIYo9EVEaohCX0Skhij0RURqiEJfRKSGKPRFRGqIQl9EpIYo9EVEaohCX0Skhij0RURqiEJfRKSG\nKPRFRGqIQl9EpIYo9EVEaohCX0Skhij0RURqiEJfRKSGKPRFRGqIQl9EpIYo9EVEaohCX0Skhij0\nRURqiEJfRKSGKPRFRGqIQl9EpIYo9EVEaohCX0Skhij0RURqiEJfRKSGJErZyMwuAB4C7nL31cet\nuw74WyAL/Nzd/6aw/C7gUiAP3OHuL5rZfOCfgTpgF/DH7n4srJ0REZGJnXKkb2YtwN3AEyfZ5B+A\nzwCXA58ws2VmdiWwxN0vA24DigeKrwPfdfcrgO3An06u+SIicjpKmd45BlwP9B6/wswWAfvd/T13\nzwGPANcWfh4EcPeNQIeZtQNXAQ8Xnv4QcN1kd0BEREp3yukdd88AGTM70erZQN+Yx7uBxUAXsG7M\n8j2FbVvGTOfsBuZM9N4dHc0kEnWnauKEksm2ST2/mqgvxlN/jKf+GFXNfVHSnP4EYid4nJ9gef4E\ny07qwIHhSTUumWyjr+/QpF6jWqgvxlN/jKf+GFUNfTHRQWuyob+TYARf1ENwgjZ93PK5BCP7ITNr\ncvcjY7aVMTLZHOlMjlQmRzqTDX5PF5dlC8uDdalMjnQ6WD7ynOLjbPH3YNtEfR2N9XVMb2lgRmsD\n7S0NTG+ZxvSWBqa3NtDWXE9dXBdziVS7SYW+u283s3YzOwvYAdwAfI5geudrwD1mthzodfdDZraG\n4KTvjwt//mIy7x91h4ZT/L+173D4SGokrFPpMQE9JryLgZ3LT/jhp2xiQFtzPe0t05je2jByMBg5\nMIw8bqBpWoJY7PgPcyIyFZwy9M1sJfBt4CwgbWY3E5yM3ebuDwBfBH5S2Pyn7r4Z2Gxm68xsLZAD\nbi+s/yrwIzP7c+Ad4Idh7kzUvPxWP7986b33La+Lx2ioj1OfqKMhEae1qZ76RJyGRF3hzzj19cG6\nhkScRGFdsPy47RKjr1NcN7p8dNuurla2vbufgaFU8HM4xcDQscKfoz/7Bo+wo+/whPuVqIuPOwhM\nbx1zYGhpoL119Pf6SZ6TEZFwxfIVGlmWoq/v0KQaV+m5uV++9B4/WfMWt3zcWL40WQjxOuLxMz9K\nPp2+OJbOMjj2wDDyeypYPmZZNjfxX1HztMS4g8OsjiZWLE0yv7u1op8WKv1vI2rUH6OqoS+SybaT\n/uea7Jy+TCCdyQHQ0dZIe3NDhVtTumn1dSRnNJGc0TThdvl8nqGjGQYOHxv3CWLcgaGwbNe+0ZPy\nD/9mO13TG1lpSVYu7WZRTztxTReJnBEK/TJKpbMANCSq8wRpLBajtame1qZ6epITb5vJ5hgcSvF2\n7yDrNvexYUs/j73wHo+98B7TWxtYsSTJSkuydP4MEnXV2V8ipSqe2yvHYEihX0bpbDDSr6/S0D8d\nibo4M9sbmdneyAfO7SadybJx+wHWbe7jlbf6eerlnTz18k5aGhNcvKSLlUu7Of/sDp0TkJrSP3CE\nZ17p5dkNvcxLtvKf/3B56O+h0C+jdFqhfzL1iTouOqeLi87pIpvLsfm9AdZ7H+s27+U3r+3mN6/t\nZlpDHRcu6mSlJfm9RZ00TdM/V6k+uXyejdv28+T6nWzY2k8+Dy2NCVYsPcXH59+R/heVkUb6pamL\nxzlvYQfnLezgDz+6hG2FKaB1vpcX3wx+EnVxLjh7JiuWJrl4SRetTfWVbrbIpBw+kubXr+7i6Zd3\nsvfgEQDOntPG1cvnccl53TTUl+dTrkK/jFKFkX6DpihKFo/FWNwzncU90/mDqxazo2+Idb43mAba\n0s8rW/qJx2LYghmstCTLlyTpaJtW6WaLlGzbrkGeWr+T5zftIZ3JUZ+Ic/nvzeaaFfM4e0572d9f\noV9GGulPTiwWY353K/O7W/nUFYvYvX+Y9Zv7WOd9bHrnAJveOcCPH9/M4p52Vi7tZoUl6T7FFUci\nlZBKZ3lh016eenkH23YFl4N2z2jiquU9fPjCOWf0k6tCv4zShat3FPrhmD2zmesvXcj1ly5k/+BR\n1m/uY/3mPvy9g2zdOci/PLWFBd2trLAkK5cmmdvVUtF7AfL5PEdTWQaHUxwaSjM4HFzOWnx86EiK\nRF2clsZ6WpoStDQGV0IVf29pqqe1MUHjtIQuaZ2i9h4Y5umXe/nVq70MHc0QAy4+p4trVvSw7OyZ\nFfl7VeiXkUb65TOzvZHrPjCf6z4wn8GhFK9s6Wed97Fx+37e3XuYB3+1jdkzm1lpSVYsTXLW7LZQ\nDgDZXI7Dw2kGhlIcGk4XAjzFwHHBfmg4xeBweuRejcmIx2I0NyZGDgItTfW0jDyuH/c4OHAEvzfp\nYFERuVyeV7fu48mXd/D62/uBoMTJJy9byJUXzaWrwp9GFfpllMrkiMdiuu68zNpbGvjIRXP5yEVz\nGT6a4dWt/azb3Mdrb+/jkefe4ZHn3mFm+zRWLA0+ASyZN2PkucXReDGkR0fiKQYLIT523eEj6VO2\nJyhTUU9PVwvtLQ20NzfQ1lJPe3PD6OPmetqaG8hmcwwdzXD4aJqhI8HP4aOZ4PejaYaOjFl3NEP/\nwSOnvAu6KAajB4vCAWHkU8SY5W1N9axqa/xdu18KBodT/GpDL0+/3Mu+waMAnNMznWtW9LDSuiMz\n+FPol1HxJI2cOc2NCS49fzaXnj+bY+ksr7+9n/Wb9/LKln2seWkHa17aQVtzPbM7W9g/cJRDw0Ex\nvFNpaUzQ3tJAT1cLbS0NtDePhnhbcwPtLfUjgd7YUHdanyq6TmP/igep4gFh6GhwMDh8JD3uQDF0\ndPwBZN/A0QkPFg33v8aFizu55LxZXLi4s2xXjlSbfD7P1t5Bnly/g5fe3Esmm6ehPs6VF8/l6uU9\nLJgVvbr8Cv0yUuhX1rT6uqDUgyXJZHO8+U5wM9jLm/vY1jtIe0s9c7pagvBurj9hgLcVRuVR+bQW\ni8VompagaVqCrumlPy+fz5NK5xg6mh5zgAg+RewbOMorW/bxkvfxkvfR2FDH8iVJVi3rZtlZMyOz\n71FyLJXltxt389T6nby7NyhQOHtmM1ev6OHyC+bQ3BjdaI1uy6pAKp1V6EdEoi7OBYs6uWBRJ5//\nmJFMttHfP3E10WoSi8WY1lDHtIY6Zra/fyrnzz9zEevf2MXzm/bwwsa9PPfGbp57YzctjQlWWjer\nls3C5s+oSLHAKNm1b4in1u/kN6/v5sixDPFYjJWW5JrlPZy7sGNKlBxX6JdROpujUR+TIycWi02J\n/5xnUiwWY8GsNhbMauPmKxfzdu8gz2/cw4tv7uXZDUFZgOktDXzw3G4uWTaLxXPba6YPs7kcr7zV\nz5Prd7LpnQMATG9p4KMfOIsrL+6ZcveJKPTLKJ3O0dY0daprikBwACjeIPfvrl2Cv3eQFzbt4aU3\n97Jm3Q7WrNtBZ3sjlyzrZtV5sypeJrtcDh4+xrMbennmlV4OHAq+2vvcBTO4esU8li/pmrLTXgr9\nMkpnNacvU1s8HhspkfG5jy5l4/b9PL9xLy+/1cejv32XR3/7LnM6m7nkvFlccl43czpbKt3kScnn\n87y2tZ8HnnyL9Zv7yObyNDbUcc2KHq5e3kNPsrXSTZw0hX6Z5PN50plc1ZZVltqTqItz4eIuLlzc\nRSqd5bW39/H8pr1s2NLPQ7/exkO/3saC7lZWLZvFB8/rpmt6dO+OzuZy9B08yq7+IXr3DbFr3zC7\n9g3Ru2+YY6ngpsqeZAvXrJjHpctmVVWxv+rZk4jJ6MYsqWIN9XWstG5WWjdHjmV4ZUs/L2zcw+vb\n9vOvT2/lX5/eyuKedi45bxYfPLebGa2VmfdOpbPs3j8cBHt/EOy79g2z58Awmez4S1gTdTFmzWzG\nFs7kEkuyZN70qpy2UuiXSfHab4W+VLumaQkuO382l50/m8NH0qzf3MfzG/fw5rsH2LpzkPueeItz\nF3RwyXnBQaIcdWaGj6bp3TfMrv4g1IPR+xD9B49y/N0JjQ11zO9uY25nM3O6WpjT2czczha6ZjRS\nF49XxdclTkShXyZphb7UoNam+pG7owcOH+Ml7+P5TXvGFcg7/+yZrDpvFhcv6TqtaZN8Ps/AUKow\nJTM6au/tH2JgKPW+7dub61k6f8a4YJ/T2UxH27SqHMGXSqFfJsWRvsoqS62a3jqNa1fO49qV8+gf\nOMKLb+7lhY17eXXrPl7duo/6RJwLF3ey6ri7gHO5PP0DR0aDvX90vv3Iscz73qezvZELFs1kbmcL\ncwsBP6ezRd+5cBIK/TLRSF9kVNf0Jj6xaiGfWLWQ3fuHeWHTHp7fuId1HpTKntZQh82fwYFDx9i9\nf/h9herq4jG6O5pYtrCDOV1BqM/tbGH2zGamNWhgdToU+mWSzqisssiJzJ7ZzL+5/Gxu/NBZ7Ogb\nGjkAvLp1Hw318WAaZiTYgz+7O5qm7HXxUaPQL5OUvh9XZEJjvyTn0x9ZxKHhNK3N9SoHXWYK/TIp\n1tLXdfoipxaLxWhv0d3rZ4ISqUzSIyN9zTeKSHQo9MtE35olIlGkRCqTVOH7cTW9IyJRokQqE430\nRSSKlEhlojl9EYkihX6ZaKQvIlGkRCoTzemLSBQpkcpEI30RiSIlUpmkdUeuiERQSXfkmtldwKVA\nHrjD3V8cs+4m4E7gGHCfu682szjwj8AFQAr4gru/aWZ3A5cBhwtP/5a7PxLa3kSIRvoiEkWnDH0z\nuxJY4u6Xmdky4AfAqsK6OLAaWAHsAx41sweBDwLT3f1DZrYY+HvgBqAVuM3dXynL3kRIsfaOSiuL\nSJSUMgy9FngQwN03Ah1m1l5Y1wUcdPc+d88BTwDXAUuAFwrP2QosNLM6oC3k9keWqmyKSBSVMr0z\nG1g35vGewrJBoA9oM7MlwHbgauBp4FXgL83sO8A5wCKCA0Qr8FUz6wB2AH/h7vtP9sYdHc0kJjlS\nTiYrc5yJFcrAzpndTnNjNL7MoVJ9EVXqj/HUH6OquS9KCf3j65zGCOb2cfe8md0C3AsMANuAmLs/\namaXA88SHAA2FZ53D/CGu282s68AXwO+dLI3PnBg+DR3Z7xKftfl4cLXtw0ODDN0qPKj/Wr/3s/T\npf4YT/0xqhr6YqKDVimhv5NgZF80F9hdfODuzwBXAJjZNwhG/Lj7ncVtzGwrsNfdHxjzOg8A3yvh\n/aekdDZHPBajLl75wBcRKSolkR4HbgYws+VAr7uPHAbN7FEzS5pZC3AjsMbMLjKzewvrPw6sd/ec\nmT1sZgsKT70KeD3EfYmUdDpHfb0CX0Si5ZQjfXdfa2brzGwtkANuN7NbgYHCyP37wC+BIeBOd+83\ns/1A3MyeAw4CtxRebjXwMzMbKmz/J6HvUUSksznq9fVuIhIxJV2n7+5fPm7RhjHr7gfuP277HHDr\nCV7ncYJPDlUvlc7SoJG+iESMUqlMNNIXkShSKpVJOp1TWWURiRyFfpmkszndmCUikaNUKoN8Pk86\nk1NZZRGJHKVSGaQzKrYmItGkVCoDVdgUkahSKpVBSrX0RSSilEplUBzpq6yyiESNQr8M0oXvx1UZ\nBhGJGqVSGYzM6evmLBGJGKVSGYx8a5ZG+iISMUqlMtBIX0SiSqlUBumRq3d0IldEokWhXwa6Tl9E\nokqpVAapwtU7KsMgIlGjVCoDlWEQkahSKpXBaOhrTl9EokWhXwapTOHmLI30RSRilEplUBzpa05f\nRKJGqVQGmtMXkahSKpWBQl9EokqpVAap4vROvU7kiki0KPTLYGSkrzIMIhIxSqUySGdUWllEokmp\nVAYa6YtIVCmVymB0Tl/dKyLRolQqg3Q2RzwWoy6u7hWRaFEqlUE6ndN8vohEkpKpDFKZrObzRSSS\nlExlkM7kNJ8vIpGkZCqDdCankb6IRJKSqQzSmZzKKotIJCn0yyCVyanujohEUqKUjczsLuBSIA/c\n4e4vjll3E3AncAy4z91Xm1kc+EfgAiAFfMHd3zSz+cA/A3XALuCP3f1YmDtUafl8nkw2p7LKIhJJ\np0wmM7sSWOLulwG3AavHrIsXHl8PfAS40czmATcB0939Q8CfAf+z8JSvA9919yuA7cCfhrcr0TBy\nN65O5IpIBJWSTNcCDwK4+0agw8zaC+u6gIPu3ufuOeAJ4DpgCfBC4TlbgYVmVgdcBTxceO5DhW2r\nSjqrEgwiEl2lTO/MBtaNebynsGwQ6APazGwJwcj9auBp4FXgL83sO8A5wCKCA0TLmOmc3cCcid64\no6OZxCRPiCaTbZN6/umKDxwBoK112hl/71OJWnsqTf0xnvpjVDX3RSmhHzvB4zyAu+fN7BbgXmAA\n2AbE3P1RM7sceJbgALBp7POOf52TOXBguJR9OKlkso2+vkOTeo3TtfdgEPq5TO6Mv/dEKtEXUab+\nGE/9Maoa+mKig1Ypob+TYGRfNJdglA6Auz8DXAFgZt8gGPHj7ncWtzGzrcBeYMjMmtz9CNBDcDK3\nqqTTKqssItFVSjI9DtwMYGbLgV53HzkMmtmjZpY0sxbgRmCNmV1kZvcW1n8cWF+Y818DfKbw1M8A\nvwhvV6IhpbLKIhJhp0wmd18LrDOztcDdwO1mdquZ/X5hk+8DvyQ4ONzp7v3Aa0DczJ4D7gBuL2z7\nVeAWM/sVMBP4Yah7EwFplVUWkQgr6Tp9d//ycYs2jFl3P3D/cdvngFtP8Dq7gI+ediunEH2BiohE\nmZIpZCOhrzIMIhJBCv2QpYrfj6s7ckUkgpRMIRuZ01foi0gEKZlCNjq9o64VkehRMoVMc/oiEmUK\n/ZAV5/R1yaaIRJGSKWS6ZFNEokzJFDKVVhaRKFMyhUxlGEQkypRMIRstw6ATuSISPQr9kKWLN2dp\npC8iEaRkCpnm9EUkypRMIdOcvohEmZIpZCqtLCJRpmQKWTqTIx6LURdX14pI9CiZQpbO5DSfLyKR\npXQKWSqTVYVNEYkspVPI0pmcKmyKSGQpnUIWhL5uzBKRaFLohyydyelyTRGJLKVTyFKZnC7XFJHI\nUjqFKJfPk8lqpC8i0aV0ClFGJRhEJOKUTiFSCQYRiTqlU4hUVllEok6hHyKVVRaRqFM6hUhllUUk\n6pROIdKcvohEndIpRCqrLCJRp3QK0cj0jsowiEhEKfRDlNb0johEnNIpRKnC1Tua3hGRqFI6hUgj\nfRGJukQpG5nZXcClQB64w91fHLPuJuBO4Bhwn7uvNrNW4EfATKAB+Jq7P2Zm/xfoADKFp/9Hd18X\n2t5UmC7ZFJGoO2Xom9mVwBJ3v8zMlgE/AFYV1sWB1cAKYB/wqJk9CHwKcHf/r2Y2F3gSOBdoBW5w\n94Nl2ZsKG71kUydyRSSaShmSXgs8CODuG4EOM2svrOsCDrp7n7vngCeA64B+oLOwTUfhMUBbWA2P\norTm9EUk4kqZ3pkNjJ2C2VNYNgj0AW1mtgTYDlwNPO3u3zSzW81sC0Hof7Lw3Fbgu2a2AHgN+Ct3\nP3qyN+7oaCYxycsfk8kzd5ypb6gP3rOz9Yy+b6mi2KZKUn+Mp/4YVc19UUrox07wOA/g7nkzuwW4\nFxgAtgExM/sj4F13/7iZXQT8L+CDwDeAx4HdwD3A7cC3T/bGBw4Mn97eHCeZbKOv79CkXuN0DAwe\nAWBo6OgZfd9SnOm+iDr1x3jqj1HV0BcTHbRKCf2dBCP7orkEoQ2Auz8DXAFgZt8gGPFfCTxWWL/B\nzHrMLOHuPyw+rzD3/9mS92IKUBkGEYm6UtLpceBmADNbDvS6+8hh0MweNbOkmbUANwJrgC2Mnuxd\nCBwG8mb2xJjzAVcBr4e1I1Gg0soiEnWnDH13XwusM7O1wN3A7YX5+t8vbPJ94JcEB4c73b2fYOrm\nLDN7BvjfwBfcPUtw5c9TZvYsMB/4buh7VEEqrSwiUVfSdfru/uXjFm0Ys+5+4P7jtj8M/NsTvM6P\ngR+ffjOnBl2nLyJRp3QKUXFOvyGhbhWRaFI6hWi0yqa6VUSiSekUonQmR108Rl1c3Soi0aR0ClEq\nkyWhUb6IRJgSKkTpTE7z+SISaUqoEKUzOc3ni0ikKaFCFIS+bswSkehS6IcolcnpxiwRiTQlVIjS\nmZzKKotIpCmhQpLL58lkNdIXkWhTQoUkoxIMIjIFKKFCorLKIjIVKKFCorLKIjIVKPRDMlJWWdfp\ni0iEKaFCklKxNRGZApRQIUmrrLKITAFKqJCorLKITAVKqJCMhr5O5IpIdCn0Q5LS9+OKyBSghArJ\n6CWb6lIRiS4lVEjSujlLRKYAJVRI0irDICJTgBIqJKNlGHQiV0SiS6EfkuIduZrTF5EoU0KFRHP6\nIjIVKKFCktKcvohMAUqokIyWYdCcvohEl0I/JKqyKSJTgRIqJCq4JiJTgRIqJMU5/YRCX0QiTAkV\nEo30RWQqUEKFRKWVRWQqUEKFJJ3JURePURdXl4pIdCmhQpLKZDWfLyKRlyhlIzO7C7gUyAN3uPuL\nY9bdBNwJHAPuc/fVZtYK/AiYCTQAX3P3x8zsIuB7hdd51d2/GOreVFA6k9N8vohE3ilTysyuBJa4\n+2XAbcDqMevihcfXAx8BbjSzecCtgLv7VcDNwN8XnvIdgoPG5UCnmX0ivF2prHQmp/l8EYm8UlLq\nWuBBAHffCHSYWXthXRdw0N373D0HPAFcB/QDnYVtOoB+M2sAzh7zKeGhwrZVIQh93Y0rItFWyvTO\nbGDdmMd7CssGgT6gzcyWANuBq4Gn3f2bZnarmW0hCP1PEhwgDox5nd3AnIneOJlsi5W4HxO9xmRf\noiQ//nr0P7Scqb6YKtQf46k/RlVzX5Qy0j8+eGMEc/K4ex64BbgXeADYBsTM7I+Ad939HOAa4O6J\nXkdERM6MUkJ/J8HIvmguwSgdAHd/xt2vcPcbgAGCEf/lwGOF9RuAHmAvo1M+FJbtmkzjRUTk9JQS\n+o8TnIzFzJYDve5+qLjSzB41s6SZtQA3AmuALcCqwvqFwGF3TwNvmtmHC0/9NPCL0PZEREROKZbP\nn3qGxcz+juDqnBxwO7AcGHD3B8zs08B/A4aAb7n7g4VLNu8FZhGcN/hrd3/SzJYB9xAcbJ53978q\nx06JiMiJlRT6IiJSHXRhuYhIDVHoi4jUkJLKMEw1E5WNqEVm9j+AKwj+vr/h7vdXuEkVZWZNwBvA\n1939nyrcnIoys88B/wXIEJx7+3mFm1QxJysfU9lWha/qRvoTlY2oRWZ2NXBBoT8+TlAKo9bdCeyr\ndCMqzcw6ga8CHwZuAD5V2RZV3K2cuHxMVam60GfishG16FngDwq/HwBazKxm60WY2bnAMuCRSrcl\nAq4D1rj7IXff5e7/vtINqrD3lY+pYFvKphpDfzZBeYiiYtmImuTuWXcfKjy8Dfi5u2cr2aYK+zag\nS4UDZxHcQf9TM/uVmV1b6QZVkrvfBywolI95FvhPFW5SWVRj6KvcwwkUSmD/GfAfKt2WSjGzzwPP\nufu2SrclImLAPOBzBFMbPzCzSde7mqpOUj6m6lRj6E9YNqIWmdnHgK8An3D3gUq3p4I+CdxkZr8l\n+NTz12ZWNZVefwd7gLXunnH3rcAhIFnhNlXS+8rHmFnVXexSdTtEUDbia8A9JyobUWvMbDrwLeA6\nd99f6fZUkrt/tvi7mf13YLu7r6lciyruceCfzOybBFestFKl89glKpaP+dmY8jGZCrcpdFUX+u6+\n1szWmdlaRstG1LLPEpS1/hczKy77vLu/W7kmSRS4+04z+z/Ak0Az8KXC92LUqnuAe83sGYJs/EKF\n21MWKsMgIlJDqnFOX0RETkKhLyJSQxT6IiI1RKEvIlJDFPoiIjVEoS8iUkMU+iIiNeT/A1TDaP7T\ntIVnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1955d94c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot metrics\n",
    "#pyplot.plot(keras_model.history['mean_squared_error'])\n",
    "#pyplot.plot(history.history['mean_absolute_error'])\n",
    "#pyplot.plot(history.history['mean_absolute_percentage_error'])\n",
    "plt.plot(history.history['r2_keras'])\n",
    "plt.ylim(0.98)\n",
    "#plt\n",
    "#pyplot.plot(history.history['cosine_proximity'])\n",
    "#pyplo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'res':pipe.predict(X) - y}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.141747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.116561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.649170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.470163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.438334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.764729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.188929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.787260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.926689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.912756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.238887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.635511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.054961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.337784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.329667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.070793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.159663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.090967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.747746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.753294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.619551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.108406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.484912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.337796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.060255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.539659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.935522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.478814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>1.906372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>3.805795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>-1.941251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.024565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>1.542695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.692880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>-1.264254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>-1.466043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>1.032130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>1.943351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-1.292359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-0.803891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-2.264104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>-4.131055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>-2.620607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1.598686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1.327379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1.176171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>-2.692484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>1.061049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>-1.147829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.918625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2.426822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-1.592161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-1.472409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.831036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.592750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.182701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.214295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          res\n",
       "0    1.141747\n",
       "1    1.116561\n",
       "2    1.649170\n",
       "3    1.470163\n",
       "4    0.438334\n",
       "5   -2.764729\n",
       "6   -0.188929\n",
       "7   -2.943000\n",
       "8    0.735384\n",
       "9   -0.787260\n",
       "10   0.926689\n",
       "11   4.912756\n",
       "12   2.238887\n",
       "13  -1.635511\n",
       "14  -0.054961\n",
       "15   1.337784\n",
       "16   0.329667\n",
       "17  -0.070793\n",
       "18   1.159663\n",
       "19  -1.090967\n",
       "20   1.747746\n",
       "21   2.753294\n",
       "22  -1.619551\n",
       "23   0.108406\n",
       "24  -0.484912\n",
       "25  -0.337796\n",
       "26   0.060255\n",
       "27  -1.539659\n",
       "28  -0.935522\n",
       "29   1.478814\n",
       "..        ...\n",
       "970  1.906372\n",
       "971  3.805795\n",
       "972 -1.941251\n",
       "973  0.024565\n",
       "974  1.542695\n",
       "975  0.692880\n",
       "976 -1.264254\n",
       "977 -1.466043\n",
       "978  1.032130\n",
       "979  1.943351\n",
       "980 -1.292359\n",
       "981 -0.803891\n",
       "982 -2.264104\n",
       "983 -4.131055\n",
       "984 -2.620607\n",
       "985  0.260870\n",
       "986  1.598686\n",
       "987  1.327379\n",
       "988  1.176171\n",
       "989 -2.692484\n",
       "990  1.061049\n",
       "991 -1.147829\n",
       "992  0.918625\n",
       "993  2.426822\n",
       "994 -1.592161\n",
       "995 -1.472409\n",
       "996  0.831036\n",
       "997 -0.592750\n",
       "998  1.182701\n",
       "999  0.214295\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efeb5865358>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efeb64dd128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
